{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk pandas spacy  gensim"
      ],
      "metadata": {
        "id": "ndii-bOE_Odd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "hAVr5GwE_a6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihKrZgtz_h6-",
        "outputId": "f024ab48-0650-4524-c96d-3fc311811c0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AsBWGnV-LP2",
        "outputId": "91d4c932-fe01-480e-bd0d-1421ceda85aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please input the article text: Whether you dip it, drizzle it, or put it on chicken nuggets or french fries, McDonald’s sauce assortment is expanding this fall.  The fast food chain announced Tuesday that it's adding two new limited-edition sauces to its U.S. menu in two weeks.  The new sauces — McDonald’s Sweet & Spicy Jam and McDonald’s MamboSauce — will hit the menu on Oct. 9, according to a news release from the company.  Are whoppers really too small?Burger King must face whopper of a lawsuit alleging burgers are too small, says judge  What are McDonald's two new sauces?  Here's more about the new limited-edition duo: • Sweet & Spicy Jam: The chain describes it as a breakfast-inspired \"jammy red pepper dipping sauce with a tongue-numbing Szechuan peppercorn kick.\" It also includes apple cider vinegar and cayenne pepper. • MamboSauce: This one is described by McD's as \"a tomato-based, sweet, spicy and vinegary sauce, inspired by an Washington, D.C. area sauce staple.\"  The company came up with the new sauces by exploring \"the incredible tastes and flavors found in communities across the country,\" Tariq Hassan, chief marking and customer experience officer at the chain, said in a news release.  The sauces \"live at the intersection of flavor and culture-pulling from decades of rich food history and tradition in local restaurants and home kitchens, and bringing the delicious spice, sweetness and kick of heat we know today’s customers are craving,\" Hassan said.  McD's said it's teaming up with six foodie content creators to review the sauces so they can share pairing suggestion ideas with customers on their respective TikTok channels.  The creators are: @Mr.Eats305, @sharidyonne, @santanakeish, @misslegarda, @natelovlogs and @blackgirlsexploredc.  \"We’re passing the mic to some of our biggest sauce fans — food content creators — to get their authentic reactions from the very first, drizzle, dip and bite,\" Hassan said.  The creators are: @Mr.Eats305, @sharidyonne, @santanakeish, @misslegarda, @natelovlogs, and @blackgirlsexploredc.  Natalie Neysa Alund is a senior correspondent for USA TODAY. Reach her at nalund@usatoday.com and follow her on X, the platform formerly known as Twitter @nataliealund.\n",
            "Cleaned Article:\n",
            "dip drizzle chicken nugget french fry mcdonald sauce assortment expand fall fast food chain announce tuesday add new limitededition sauce menu week new sauce mcdonald sweet spicy jam mcdonald mambosauce hit menu oct accord news release company whopper small?burg king face whopper lawsuit allege burger small say judge mcdonald new sauce new limitededition duo sweet spicy jam chain describe breakfastinspire jammy red pepper dipping sauce tonguenumbing szechuan peppercorn kick include apple cider vinegar cayenne pepper mambosauce describe mcd tomatobase sweet spicy vinegary sauce inspire washington dc area sauce staple company come new sauce explore incredible taste flavor find community country tariq hassan chief marking customer experience officer chain say news release sauce live intersection flavor culturepulle decade rich food history tradition local restaurant home kitchen bring delicious spice sweetness kick heat know today customer crave hassan say mcd say team foodie content creator review sauce share pairing suggestion idea customer respective tiktok channel creator mreat sharidyonne santanakeish misslegarda natelovlog blackgirlsexploredc pass mic big sauce fan food content creator authentic reaction drizzle dip bite hassan say creator mreat sharidyonne santanakeish misslegarda natelovlog blackgirlsexploredc natalie neysa alund senior correspondent usa today reach nalundusatodaycom follow x platform know twitter nataliealund\n",
            "\n",
            "Mood Rating: Positive\n",
            "\n",
            "Aspect Analysis:\n",
            "chicken nugget french fry mcdonald sauce assortment expand: Positive\n",
            "fast food chain announce: Neutral\n",
            "new sauce mcdonald sweet spicy jam mcdonald mambosauce: Positive\n",
            "king: Neutral\n",
            "whopper lawsuit allege burger small: Negative\n",
            "judge mcdonald new sauce new limitededition duo sweet spicy jam chain describe breakfastinspire jammy red pepper dipping sauce tonguenumbing szechuan peppercorn kick: Positive\n",
            "apple cider vinegar cayenne pepper mambosauce describe mcd tomatobase sweet spicy vinegary sauce inspire washington dc area: Positive\n",
            "staple company: Neutral\n",
            "new sauce: Neutral\n",
            "incredible taste flavor: Neutral\n",
            "community country: Neutral\n",
            "tariq hassan chief mark customer experience officer chain: Neutral\n",
            "news release: Neutral\n",
            "live intersection flavor: Neutral\n",
            "customer crave hassan: Neutral\n",
            "mcd: Neutral\n",
            "team foodie content creator review sauce share pairing suggestion idea customer respective tiktok channel creator mreat sharidyonne santanakeish misslegarda natelovlog blackgirlsexploredc: Positive\n",
            "mic big sauce fan food content creator authentic reaction: Positive\n",
            "drizzle dip bite hassan: Neutral\n",
            "creator mreat sharidyonne santanakeish misslegarda natelovlog blackgirlsexploredc natalie neysa: Neutral\n",
            "senior correspondent usa: Neutral\n",
            "nalundusatodaycom follow x platform: Neutral\n",
            "twitter nataliealund: Neutral\n",
            "\n",
            "Themes: sauce, say, new\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "# Load Spacy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean the text by removing unnecessary characters and converting to lowercase.\n",
        "    \"\"\"\n",
        "    # text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # text = text.lower().strip()\n",
        "    # return text\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Replace common contractions\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = text.replace('(ap)', '')\n",
        "    text = re.sub(r\"\\'s\", \" is \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    # Remove non-alphanumeric characters except for '?', '!', and ' '\n",
        "    text = re.sub(r'[^a-zA-Z?! ]+', '', text)\n",
        "    # Remove non-ASCII characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "    # Remove extra spaces and newlines\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clean_article(article):\n",
        "    \"\"\"\n",
        "    Process article texts by cleaning, removing stop words, and applying lemmatization.\n",
        "    \"\"\"\n",
        "    doc = nlp(clean_text(article))\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "def analyze_mood(article):\n",
        "    \"\"\"\n",
        "    Determine the mood of the article using VADER.\n",
        "    \"\"\"\n",
        "    score = sid.polarity_scores(article)['compound']\n",
        "    return \"Positive\" if score >= 0.05 else \"Negative\" if score <= -0.05 else \"Neutral\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def aspect_sentiment_analysis(article):\n",
        "    \"\"\"\n",
        "    Extracts aspects from the article and evaluates their sentiment,\n",
        "    ensuring both positive and negative sentiments are considered.\n",
        "    \"\"\"\n",
        "    doc = nlp(article)\n",
        "    aspects = {}\n",
        "    for chunk in doc.noun_chunks:\n",
        "        # Extract the root word of the chunk as the aspect\n",
        "        aspect_text = ' '.join([token.lemma_ for token in chunk])\n",
        "        # Use VADER to determine sentiment of the whole chunk\n",
        "        sentiment_score = sid.polarity_scores(chunk.text)['compound']\n",
        "        if sentiment_score >= 0.05:\n",
        "            sentiment = \"Positive\"\n",
        "        elif sentiment_score <= -0.05:\n",
        "            sentiment = \"Negative\"\n",
        "        else:\n",
        "            sentiment = \"Neutral\"\n",
        "        aspects[aspect_text] = sentiment\n",
        "    return aspects\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def find_connections(article, n_keywords=3):\n",
        "    \"\"\"\n",
        "    Identify key themes within an article using TF-IDF for keyword extraction.\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform([article])\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "    sorted_indices = np.argsort(tfidf_matrix.toarray()).flatten()[::-1]\n",
        "    top_keywords = feature_names[sorted_indices][:n_keywords]\n",
        "    return ', '.join(top_keywords)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Perform analysis on the input article provided by the user and display the results.\n",
        "    \"\"\"\n",
        "    # Take article input from the user\n",
        "    article = input(\"Please input the article text: \")\n",
        "\n",
        "    # Perform analysis\n",
        "    clean_textt = clean_text(article)\n",
        "    cleaned_article = clean_article(clean_textt)\n",
        "    mood = analyze_mood(cleaned_article)\n",
        "    aspect_analysis = aspect_sentiment_analysis(cleaned_article)\n",
        "    themes = find_connections(cleaned_article)\n",
        "\n",
        "    # Display results\n",
        "    print(\"Cleaned Article:\")\n",
        "    print(cleaned_article)\n",
        "    print(\"\\nMood Rating:\", mood)\n",
        "    print(\"\\nAspect Analysis:\")\n",
        "    for aspect, sentiment in aspect_analysis.items():\n",
        "        print(f\"{aspect}: {sentiment}\")\n",
        "    print(\"\\nThemes:\", themes)\n",
        "\n",
        "# Call the main function\n",
        "main()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "zfl16syi_iyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b1bmxLF7_pyJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}